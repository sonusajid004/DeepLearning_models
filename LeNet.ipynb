{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIMwtg6myQfTSWY+f0mAAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonusajid004/DeepLearning_models/blob/master/LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xt_yAXmGU84",
        "colab_type": "text"
      },
      "source": [
        "Here i am using Lenet to categorize digits i.e. use MNIST dataset.\n",
        "\n",
        "\n",
        "Letnet's architechture is ..\n",
        "\n",
        "[Image Source](https://engmrk.com/lenet-5-a-classic-cnn-architecture/)\n",
        "\n",
        "![Lenet Summary ](https://engmrk.com/wp-content/uploads/2018/09/LeNEt_Summary_Table.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKXtE8RpGREJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu',kernel_initializer=\"he_uniform\" ,input_shape=(28,28,1)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu',kernel_initializer=\"he_uniform\"))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu',kernel_initializer=\"he_uniform\"))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFEnb0wGIcvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "ae0f7f99-2456-41fe-9452-7e6c0da0cb9c"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 6)         60        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 13, 13, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 11, 11, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_8 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 3, 3, 16)          2320      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_9 (Average (None, 1, 1, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 120)               2040      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 16,314\n",
            "Trainable params: 16,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrPz4rLOIlZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Loading Data\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "\n",
        "# loads the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
        "\n",
        "# Lets store the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "# Getting our date in the right 'shape' needed for Keras\n",
        "# We need to add a 4th dimenion to our date thereby changing our\n",
        "# Our original image shape of (60000,28,28) to (60000,28,28,1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# store the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# change our image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Now we one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_zvoFHfIsFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb716ebe-9329-4f4d-bdc2-38067d9da3ad"
      },
      "source": [
        "# Training Parameters\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "                     \n",
        "checkpoint = ModelCheckpoint(\"./lenet.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "\n",
        "# We use a very small learning rate \n",
        "\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                      callbacks=callbacks,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "model.save(\"./mnist_LeNet.h5\")\n",
        "\n",
        "# Evaluate the performance of our trained model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.2473 - accuracy: 0.9243 - val_loss: 0.1798 - val_accuracy: 0.9429\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.17975, saving model to ./lenet.h5\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.1730 - accuracy: 0.9471 - val_loss: 0.1545 - val_accuracy: 0.9504\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.17975 to 0.15448, saving model to ./lenet.h5\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 19s 325us/step - loss: 0.1422 - accuracy: 0.9561 - val_loss: 0.1251 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.15448 to 0.12512, saving model to ./lenet.h5\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.1240 - accuracy: 0.9618 - val_loss: 0.1052 - val_accuracy: 0.9670\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.12512 to 0.10521, saving model to ./lenet.h5\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.1045 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.10521 to 0.10454, saving model to ./lenet.h5\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 0.1082 - val_accuracy: 0.9656\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.10454\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.0817 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.10454 to 0.08165, saving model to ./lenet.h5\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0891 - accuracy: 0.9723 - val_loss: 0.1012 - val_accuracy: 0.9664\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.08165\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0829 - accuracy: 0.9746 - val_loss: 0.0800 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.08165 to 0.08004, saving model to ./lenet.h5\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0779 - accuracy: 0.9759 - val_loss: 0.0810 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.08004\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0734 - accuracy: 0.9762 - val_loss: 0.0707 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.08004 to 0.07071, saving model to ./lenet.h5\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.0677 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.07071 to 0.06772, saving model to ./lenet.h5\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0671 - accuracy: 0.9791 - val_loss: 0.0683 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.06772\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0659 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.06772 to 0.06589, saving model to ./lenet.h5\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.0603 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.06589 to 0.06034, saving model to ./lenet.h5\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0582 - accuracy: 0.9818 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.06034\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.0655 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.06034\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 0.0619 - val_accuracy: 0.9811\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.06034\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 00018: early stopping\n",
            "10000/10000 [==============================] - 2s 190us/step\n",
            "Test loss: 0.06033637920781039\n",
            "Test accuracy: 0.9817000031471252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Vj7f4vI8GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "outputId": "1c4289d1-2479-4c93-adb7-ebf90004f0cf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "nb_train_samples = 28273\n",
        "nb_validation_samples = 3534\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
        "print('Classification Report')\n",
        "print(classification_report(np.argmax(y_test,axis=1), y_pred))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test,axis=1), y_pred)\n",
        "\n",
        "plt.imshow(cnf_matrix, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(10)\n",
        "_ = plt.xticks(tick_marks, np.arange(10), rotation=90)\n",
        "_ = plt.yticks(tick_marks, np.arange(10))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 968    0    1    0    0    2    2    1    3    3]\n",
            " [   0 1134    0    0    0    1    0    0    0    0]\n",
            " [   3    1 1009    1    1    3    1    6    7    0]\n",
            " [   0    0    2  994    0    8    0    3    2    1]\n",
            " [   1    0    2    1  960    0    3    1    2   12]\n",
            " [   1    0    0    2    0  883    2    1    3    0]\n",
            " [   2    3    0    0    1    5  945    0    2    0]\n",
            " [   1    4   19   13    0    1    0  986    3    1]\n",
            " [   1    0    2    3    2    2    1    1  961    1]\n",
            " [   3    0    0    1    3    9    1    3   12  977]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.97      0.98      0.98      1032\n",
            "           3       0.98      0.98      0.98      1010\n",
            "           4       0.99      0.98      0.99       982\n",
            "           5       0.97      0.99      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.98      0.96      0.97      1028\n",
            "           8       0.97      0.99      0.98       974\n",
            "           9       0.98      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mtEE2j7XfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b6e53c1-6715-405f-e3bb-92fb75d76ef7"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctJu9Or372Xy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34e8e0f7-16c1-43bc-8164-078f2744724c"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajvHy-Eg732M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}